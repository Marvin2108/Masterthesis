{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4ea6cd-223b-441c-90c7-81742e3de6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bda44c71-c82b-4f6e-b7c7-7f8392c8a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 01_LLMs_konfigurieren.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50205188-5623-430b-8f4b-01ad73507c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 02_Daten_laden.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58502c23-d9db-4970-a704-c63cc85a0a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>you wish you were at home watching that movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>'s no point in extracting the bare bones of by...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>underdeveloped</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>the jokes are flat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>a heartening tale of small victories</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                           sentence  label\n",
       "0        0       hide new secretions from the parental units       0\n",
       "1        1               contains no wit , only labored gags       0\n",
       "2        2  that loves its characters and communicates som...      1\n",
       "3        3  remains utterly satisfied to remain the same t...      0\n",
       "4        4  on the worst revenge-of-the-nerds clichés the ...      0\n",
       "..     ...                                                ...    ...\n",
       "995    995  you wish you were at home watching that movie ...      0\n",
       "996    996  's no point in extracting the bare bones of by...      0\n",
       "997    997                                    underdeveloped       0\n",
       "998    998                                the jokes are flat       0\n",
       "999    999              a heartening tale of small victories       1\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bilde ein Subset mit 1.000 Einträgen\n",
    "sst2_subset = sst2_combined[:1000]\n",
    "sst2_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9cff83b-479d-4dce-a522-b37d7e9aba90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>sentiment_coded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @TheKedosZone : So ein Hearthstone - Key vo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tainted Talents ( Ateliertagebuch. ) \" Wir sin...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aber wenigstens kommt #Supernatural heute mal ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DARLEHEN - Angebot für Schufa - freie Darlehen...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ANRUF ERWÜNSCHT : Hardcore Teeny Vicky Carrera...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>@sinkingFX Die Liebe unter Verwandten . : ' 3</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>Cros Kindermusik braucht keiner .</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>RT @ZDFsport : Extrem viele Braunschweiger hie...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>Moin Moin ... trotz Regen wünsche ich euch ein...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>RT @Geisthoernchen : @NewelMedia Tja , der IRA...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               Text Sentiment  \\\n",
       "0        0  RT @TheKedosZone : So ein Hearthstone - Key vo...  positive   \n",
       "1        1  Tainted Talents ( Ateliertagebuch. ) \" Wir sin...   neutral   \n",
       "2        2  Aber wenigstens kommt #Supernatural heute mal ...   neutral   \n",
       "3        3  DARLEHEN - Angebot für Schufa - freie Darlehen...   neutral   \n",
       "4        4  ANRUF ERWÜNSCHT : Hardcore Teeny Vicky Carrera...   neutral   \n",
       "..     ...                                                ...       ...   \n",
       "995    995      @sinkingFX Die Liebe unter Verwandten . : ' 3  positive   \n",
       "996    996                  Cros Kindermusik braucht keiner .  negative   \n",
       "997    997  RT @ZDFsport : Extrem viele Braunschweiger hie...  positive   \n",
       "998    998  Moin Moin ... trotz Regen wünsche ich euch ein...  positive   \n",
       "999    999  RT @Geisthoernchen : @NewelMedia Tja , der IRA...  negative   \n",
       "\n",
       "     sentiment_coded  \n",
       "0                  1  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "..               ...  \n",
       "995                1  \n",
       "996                0  \n",
       "997                1  \n",
       "998                1  \n",
       "999                0  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb10k_subset = sb10k_combined[:1000]\n",
    "sb10k_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5203354-255e-4348-93b1-8a25c7b9fca4",
   "metadata": {},
   "source": [
    "# Chain of thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ae42c-7b37-4df1-a4c0-53d9b1e4bfa7",
   "metadata": {},
   "source": [
    "## OpenAI / GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5fdd27-b183-4d64-9d2c-e4e6de8eeebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x16a2902c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146e592-b2f1-40e4-9aa5-b44122699455",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class CoT(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3fd864-af59-4185-95f7-0e10f2695ce0",
   "metadata": {},
   "source": [
    "### SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d00853-3d52-4419-a172-28653d6b4dc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Leeres DataFrame erstellen, um die Ergebnisse zu speichern\n",
    "results_gpt_df = pd.DataFrame(columns=['index', 'sentence','steps', 'generated_label'])\n",
    "\n",
    "# Zähler für das Einfügen in das DataFrame\n",
    "row_counter = 0\n",
    "\n",
    "## Prompts\n",
    "\n",
    "system_prompt = \"\"\"You classify sentiments of a text. Final_answer should be ONLY negative or positive!\n",
    "Analyze the text step-by-step to determine whether it expresses positive or negative sentiment.\n",
    "Explain each step in detail before providing your final answer.\"\"\"\n",
    "\n",
    "user_prompt = (\"\"\"       \n",
    "Classify the sentiment of the following text into one of these two sentiments ['negative', 'positive'].\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Schleife mit API-Call\n",
    "for index, row in sst2_subset.iterrows():\n",
    "    text = row['sentence']\n",
    "    #print(text)\n",
    "\n",
    "    try:\n",
    "        # GenAI Model-Aufruf für die Sentiment-Klassifikation\n",
    "        response = openai_client.beta.chat.completions.parse( # .chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", # gpt-3.5-turbo # gpt-4o-mini\n",
    "            messages=[\n",
    "                { # Return only 0 or 1 without additional text. Use 0 for negative and 1 for positive Sentiments.\n",
    "                \"role\": \"system\", \n",
    "                \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                 \"content\": (user_prompt + f\"Text: {text}:\")\n",
    "                }\n",
    "            ],\n",
    "            temperature = 0.2,\n",
    "            response_format=CoT\n",
    "        )\n",
    "        response_content = response.choices[0].message.parsed #response.choices[0].message.content\n",
    "        result_step = response_content.steps\n",
    "        final_answer = response_content.final_answer\n",
    "        print(response_content)\n",
    "        print(index, \" \", \"Label: \",final_answer )        \n",
    "        \n",
    "\n",
    "        # Ergebnis in das DataFrame effizient speichern\n",
    "        results_gpt_df.loc[row_counter] = [index, text, result_step, final_answer] # [index, text, steps, response_content]\n",
    "        row_counter += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fehlerbehandlung, wenn etwas beim API-Aufruf oder Speichern schiefgeht\n",
    "        print(f\"Fehler bei der Verarbeitung der Zeile {index}: {str(e)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7ac4d-b0f3-4590-a756-4424bd5562a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eeaa24-a197-4ee9-a945-ebb4a03cc7cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Datenaufbereitung \n",
    "\n",
    "# Entferne Zeilenumbrüche und Leerzeichen aus der Spalte 'generated_label'\n",
    "results_gpt_df['generated_label'] = results_gpt_df['generated_label'].str.strip()\n",
    "\n",
    "# Wandelt die Werte in Kleinbuchstaben um\n",
    "results_gpt_df['generated_label'] = results_gpt_df['generated_label'].str.lower()\n",
    "\n",
    "# Mapping: 'negative' zu 0, 'positive' zu 1\n",
    "results_gpt_df_final = results_gpt_df # [results_gpt_df['generated_label'].isin(['0', '1',0,1])]\n",
    "\n",
    "results_gpt_df_final['generated_label'] = results_gpt_df_final['generated_label'].replace({'negative': 0, 'positive': 1})\n",
    "\n",
    "# Filtert den DataFrame, um nur Zeilen zu behalten, bei denen der Wert in 'generated_label' 0 oder 1 ist\n",
    "results_gpt_df_final_ver = results_gpt_df_final[results_gpt_df_final['generated_label'].isin([0, 1])]\n",
    "\n",
    "# als int formatieren\n",
    "results_gpt_df_final_ver['generated_label'] = results_gpt_df_final_ver['generated_label'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d706e4-78f4-4ba1-9949-f52e08767908",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_gpt_df_final_ver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_gpt_df_final_ver\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_gpt_df_final_ver' is not defined"
     ]
    }
   ],
   "source": [
    "results_gpt_df_final_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9b56a-b1d6-47c8-a3aa-0566985c5696",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CSV abspeichern \n",
    "results_gpt_df_final_ver.to_csv('/Users/marvinschmitt/Library/CloudStorage/OneDrive-Persönlich/M.Sc. Data Science/17 Masterarbeit/Repo/Prod/CSVs/SC_SST2_ZeroShot_CoT_GPT.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6320f9-7bd8-46b3-b1ac-d804bb4e4563",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5176d-c42d-4f48-84c2-3b24ae61b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Annahme: Beide DataFrames haben eine Spalte 'index' als gemeinsamen Schlüssel\n",
    "# results_gpt_df: enthält die von LLM generierten Sentiment-Labels\n",
    "# sst2_subset: enthält die tatsächlichen (gold standard) Sentiment-Labels\n",
    "\n",
    "# Beide DataFrames anhand der 'index'-Spalte mergen\n",
    "df_combined = pd.merge(sst2_subset, results_gpt_df_final_ver, on='index')\n",
    "\n",
    "# Die Spalten 'label' und 'generated_label' sollten die tatsächlichen und vorhergesagten Labels enthalten\n",
    "true_labels = df_combined['label']  # Tatsächliche Labels (z.B. aus SST2)\n",
    "predicted_labels = df_combined['generated_label']  # Vorhergesagte Labels (z.B. aus GPT)\n",
    "\n",
    "# 1. Accuracy (Genauigkeit)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# 2. Precision (Genauigkeit der positiven Klassifikation)\n",
    "precision = precision_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "\n",
    "# 3. Recall (Empfindlichkeit, Trefferquote)\n",
    "recall = recall_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "# 4. F1-Score (harmonisches Mittel von Precision und Recall)\n",
    "f1 = f1_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "\n",
    "# 5. Confusion Matrix (Verwirrungsmatrix)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=[0,1])\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afd656-702a-4c5b-85dd-ae62b2b3f5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52be6c-eb6d-4b29-9fea-37e450156006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ef85f2-f528-4507-80d1-21999c7152a0",
   "metadata": {},
   "source": [
    "### SB10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389c1d3-58bd-4b75-ad5c-ea1720355cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leeres DataFrame erstellen, um die Ergebnisse zu speichern\n",
    "results_gpt_sb10k_df = pd.DataFrame(columns=['index', 'sentence', 'steps', 'generated_label'])\n",
    "\n",
    "# Zähler für das Einfügen in das DataFrame\n",
    "row_counter = 0\n",
    "\n",
    "# Schleife mit API-Call\n",
    "for index, row in sb10k_subset.iterrows():\n",
    "    text = row['Text']\n",
    "    #print(text)\n",
    "\n",
    "    try:\n",
    "        # GenAI Model-Aufruf für die Sentiment-Klassifikation\n",
    "        response = openai_client.beta.chat.completions.parse( # .chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", # gpt-3.5-turbo # gpt-4o-mini\n",
    "            messages=[\n",
    "                { # Return only 0 or 1 without additional text. Use 0 for negative and 1 for positive Sentiments.\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Du klassifizierst die Sentiments eines Textes.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                 \"content\": (f\"\"\"Klassifiziere das Sentiment des folgenden Text in ['negativ', 'neutral', 'positiv'].\n",
    "                            Analysiere den Text Schritt für Schritt, um zu bestimmen, ob er eine positive, negative oder neutrale Stimmung ausdrückt.\n",
    "                            Erkläre jeden Schritt im Detail, bevor du deine endgültige Antwort gibst.\n",
    "                            Text: {text}.\"\"\")\n",
    "                }\n",
    "            ],\n",
    "            temperature = 0.2,\n",
    "            response_format=CoT\n",
    "        )\n",
    "        response_content = response.choices[0].message.parsed #response.choices[0].message.content\n",
    "        result_step = response_content.steps\n",
    "        print(result_step)\n",
    "        final_answer = response_content.final_answer\n",
    "        print(index, \" \", \"Label: \",final_answer )          \n",
    "        \n",
    "\n",
    "        # Ergebnis in das DataFrame effizient speichern\n",
    "        results_gpt_sb10k_df.loc[row_counter] = [index, text, result_step, final_answer]\n",
    "        row_counter += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fehlerbehandlung, wenn etwas beim API-Aufruf oder Speichern schiefgeht\n",
    "        print(f\"Fehler bei der Verarbeitung der Zeile {index}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2cee9-1379-47a9-9f4c-eb1fefa9b715",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gpt_sb10k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72078c3f-a6d3-4ed2-a4d8-01e6445f12d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Entferne Zeilenumbrüche und Leerzeichen aus der Spalte 'generated_label'\n",
    "results_gpt_sb10k_df['generated_label'] = results_gpt_sb10k_df['generated_label'].str.strip()\n",
    "\n",
    "# Wandelt die Werte in Kleinbuchstaben um\n",
    "results_gpt_sb10k_df['generated_label'] = results_gpt_sb10k_df['generated_label'].str.lower()\n",
    "\n",
    "# Mapping: 'negative' zu 0, 'positive' zu 1\n",
    "results_gpt_sb10k_df_ver = results_gpt_sb10k_df # [results_gpt_sb10k_df['generated_label'].isin(['0', '1','2',0,1,2])]\n",
    "\n",
    "# Mapping: 'negative', 'negativ' zu 0, 'positive', 'positiv' zu 1, 'neutral' zu 2\n",
    "results_gpt_sb10k_df_ver['generated_label'] = results_gpt_sb10k_df_ver['generated_label'].replace({\n",
    "    'negative': 0, \n",
    "    'negativ': 0, \n",
    "    'positive': 1, \n",
    "    'positiv': 1, \n",
    "    'neutral': 2\n",
    "})\n",
    "\n",
    "# Filtert den DataFrame, um nur Zeilen zu behalten, bei denen der Wert in 'generated_label' 0 oder 1 ist\n",
    "results_gpt_sb10k_df_final = results_gpt_sb10k_df_ver[results_gpt_sb10k_df_ver['generated_label'].isin(['0', '1','2',0,1,2])]\n",
    "\n",
    "# als int formatieren\n",
    "results_gpt_sb10k_df_final['generated_label'] = results_gpt_sb10k_df_final['generated_label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ea8fa-4b80-4fd2-913a-d52b28950929",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sb10k_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5c202-4f5c-4517-b228-17c83322e724",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gpt_sb10k_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a95a8f3-0f7a-48e1-af30-bf6810ce501c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CSV abspeichern \n",
    "results_gpt_sb10k_df_final.to_csv('/Users/marvinschmitt/Library/CloudStorage/OneDrive-Persönlich/M.Sc. Data Science/17 Masterarbeit/Repo/Prod/CSVs/SC_SB10k_ZeroShot_CoT_GPT.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39e3888-d938-4845-a8bd-08eff1a2b3f5",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa3a214-07b6-4667-8ce9-8b37b3a137bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Beide DataFrames anhand der 'index'-Spalte mergen\n",
    "df_combined = pd.merge(sb10k_subset, results_gpt_sb10k_df_final, on='index')\n",
    "\n",
    "# Die Spalten 'label' und 'generated_label' sollten die tatsächlichen und vorhergesagten Labels enthalten\n",
    "true_labels = df_combined['sentiment_coded']  # Tatsächliche Labels (z.B. aus SST2)\n",
    "predicted_labels = df_combined['generated_label']  # Vorhergesagte Labels (z.B. aus GPT)\n",
    "\n",
    "# 1. Accuracy (Genauigkeit)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# 2. Precision (Genauigkeit der Klassifikation für alle Klassen)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'Precision (macro): {precision:.2f}')\n",
    "\n",
    "# 3. Recall (Empfindlichkeit für alle Klassen)\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'Recall (macro): {recall:.2f}')\n",
    "\n",
    "# 4. F1-Score (harmonisches Mittel von Precision und Recall für alle Klassen)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'F1-Score (macro): {f1:.2f}')\n",
    "\n",
    "# 5. Confusion Matrix (Verwirrungsmatrix)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=[0, 1, 2])\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a252af6-f530-4c55-b580-8992af25238f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix berechnen (true_labels und predicted_labels sind die tatsächlichen und vorhergesagten Labels)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Klassenlabels definieren\n",
    "class_names = ['negativ', 'positiv', 'neutral']\n",
    "\n",
    "# Confusion Matrix als Heatmap darstellen\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Achsen beschriften\n",
    "plt.xlabel('Vorhergesagte Labels')\n",
    "plt.ylabel('Tatsächliche Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb14fa-c414-4f81-bdd2-61b7e94a2298",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef549764-32a7-48b0-8b94-073e785ff6de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca6fff22-6541-471f-b934-9b80cd3050a0",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3251b-fbcd-4641-aa15-fd60759bcebf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "genai_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6cd1e5-ddb4-4965-9893-6998c2049d94",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13db13d9-609f-4c5f-8853-3e2658210493",
   "metadata": {},
   "source": [
    "### SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f89e32-6b95-44b8-9605-3737e24e518e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# System-Prompts\n",
    "\n",
    "genai_model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "    safety_settings='BLOCK_NONE',\n",
    "    system_instruction=\"\"\"\n",
    "    You classify sentiments of a text (ONLY negative or positive!). Use this JSON Schema: Result = {'steps':str, 'final_answer': str}\n",
    "                 \"\"\",\n",
    "    generation_config={\"response_mime_type\": \"application/json\"})\n",
    "\n",
    "\n",
    "# Leeres DataFrame erstellen, um die Ergebnisse zu speichern\n",
    "results_gemini_df = pd.DataFrame(columns=['index', 'sentence','steps', 'generated_label'])\n",
    "\n",
    "# Zähler für das Einfügen in das DataFrame\n",
    "row_counter = 0\n",
    "\n",
    "# Schleife mit API-Call\n",
    "for index, row in sst2_subset.iterrows():\n",
    "    text = row['sentence']\n",
    "\n",
    "    try:\n",
    "        # GenAI Model-Aufruf für die Sentiment-Klassifikation\n",
    "        response = genai_model.generate_content(f\"\"\"Classify the sentiment of the following text into one of these two sentiments ['negative', 'positive'].\n",
    "                            Analyze the text step-by-step to determine whether it expresses positive or negative sentiment.\n",
    "                            Explain each step in detail before providing your final answer. Your final answer should ONLY contain 'negative' or 'positive'!\n",
    "                            Text: {text}.\"\"\")\n",
    "        llm_output = response.text\n",
    "        print(llm_output)\n",
    "        \n",
    "        # dict speichern\n",
    "        resp_dict = json.loads(llm_output)\n",
    "        #print(resp_dict)\n",
    "\n",
    "        # durch dict iterieren\n",
    "        steps = resp_dict['steps']\n",
    "        final_result = resp_dict['final_answer']\n",
    "        \n",
    "        print(index, \" \", \"output:  \", final_result)\n",
    "\n",
    "        # Ergebnis in das DataFrame effizient speichern\n",
    "        results_gemini_df.loc[row_counter] = [index, text, steps, final_result]\n",
    "        row_counter += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fehlerbehandlung, wenn etwas beim API-Aufruf oder Speichern schiefgeht\n",
    "        print(f\"Fehler bei der Verarbeitung der Zeile {index}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f850c2d-6362-4b91-b40c-af8df5f5196a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gemini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525766c5-abbf-42bf-bc1c-f4b0478843b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Datenaufbereitung \n",
    "\n",
    "# Entferne Zeilenumbrüche und Leerzeichen aus der Spalte 'generated_label'\n",
    "results_gemini_df['generated_label'] = results_gemini_df['generated_label'].str.strip()\n",
    "\n",
    "# Wandelt die Werte in Kleinbuchstaben um\n",
    "results_gemini_df['generated_label'] = results_gemini_df['generated_label'].str.lower()\n",
    "\n",
    "# Mapping: 'negative' zu 0, 'positive' zu 1\n",
    "results_gemini_df_final = results_gemini_df # [results_gpt_df['generated_label'].isin(['0', '1',0,1])]\n",
    "\n",
    "results_gemini_df_final['generated_label'] = results_gemini_df_final['generated_label'].replace({'negative': 0, 'positive': 1})\n",
    "\n",
    "# Filtert den DataFrame, um nur Zeilen zu behalten, bei denen der Wert in 'generated_label' 0 oder 1 ist\n",
    "results_gemini_df_final_ver = results_gemini_df_final[results_gemini_df_final['generated_label'].isin([0, 1])]\n",
    "\n",
    "# als int formatieren\n",
    "results_gemini_df_final_ver['generated_label'] = results_gemini_df_final_ver['generated_label'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97736353-86ea-4923-95af-9d21ef474c11",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gemini_df_final_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c157101b-53f6-4bea-98c6-b32b2e025166",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CSV abspeichern \n",
    "results_gemini_df_final_ver.to_csv('/Users/marvinschmitt/Library/CloudStorage/OneDrive-Persönlich/M.Sc. Data Science/17 Masterarbeit/Repo/Prod/CSVs/SC_SST2_ZeroShot_CoT_GEMINI.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356bb0e-9c34-4576-993d-10d834c3a777",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9bebe-0585-437a-850e-97377b8f87f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Annahme: Beide DataFrames haben eine Spalte 'index' als gemeinsamen Schlüssel\n",
    "# results_gpt_df: enthält die von LLM generierten Sentiment-Labels\n",
    "# sst2_subset: enthält die tatsächlichen (gold standard) Sentiment-Labels\n",
    "\n",
    "# Beide DataFrames anhand der 'index'-Spalte mergen\n",
    "df_combined = pd.merge(sst2_subset, results_gemini_df_final_ver, on='index')\n",
    "\n",
    "# Die Spalten 'label' und 'generated_label' sollten die tatsächlichen und vorhergesagten Labels enthalten\n",
    "true_labels = df_combined['label']  # Tatsächliche Labels (z.B. aus SST2)\n",
    "predicted_labels = df_combined['generated_label']  # Vorhergesagte Labels (z.B. aus GPT)\n",
    "\n",
    "# 1. Accuracy (Genauigkeit)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# 2. Precision (Genauigkeit der positiven Klassifikation)\n",
    "precision = precision_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'Precision: {precision:.2f}')\n",
    "\n",
    "# 3. Recall (Empfindlichkeit, Trefferquote)\n",
    "recall = recall_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "# 4. F1-Score (harmonisches Mittel von Precision und Recall)\n",
    "f1 = f1_score(true_labels, predicted_labels, pos_label=1)\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "\n",
    "# 5. Confusion Matrix (Verwirrungsmatrix)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=[0,1])\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1cfa2-b5dc-4d59-9c9d-7aac0282b2f7",
   "metadata": {},
   "source": [
    "### SB10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510edf97-8034-4951-86d8-d78a4e01402b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# system-prompt gemini\n",
    "\n",
    "genai_model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  safety_settings='BLOCK_NONE',\n",
    "\n",
    "  system_instruction=\n",
    "    \"\"\"\n",
    "            Du klassifizierst die Sentiments eines Textes. Verwende dieses JSON Schema: Result = {'steps':str, 'final_answer': str}\n",
    "\n",
    "    \"\"\",\n",
    "  generation_config={\"response_mime_type\": \"application/json\"}\n",
    "    )\n",
    "\n",
    "# Leeres DataFrame erstellen, um die Ergebnisse zu speichern\n",
    "results_gemini_df = pd.DataFrame(columns=['index', 'sentence','steps', 'generated_label'])\n",
    "\n",
    "# Zähler für das Einfügen in das DataFrame\n",
    "row_counter = 0\n",
    "\n",
    "# Schleife mit API-Call\n",
    "for index, row in sb10k_subset.iterrows():\n",
    "    text = row['Text']\n",
    "\n",
    "    try:\n",
    "        # GenAI Model-Aufruf für die Sentiment-Klassifikation\n",
    "        response = genai_model.generate_content(f\"\"\"Klassifiziere das Sentiment des folgenden Text in ['negativ', 'neutral', 'positiv'].\n",
    "                            Analysiere den Text Schritt für Schritt, um zu bestimmen, ob er eine positive, negative oder neutrale Stimmung ausdrückt.\n",
    "                            Erkläre jeden Schritt im Detail, bevor du deine endgültige Antwort gibst. Die final_answer sollte NUR 'negativ', 'neutral', 'positiv' enthalten!\n",
    "                            Text: {text}.\"\"\")\n",
    "        llm_output = response.text\n",
    "        #print(llm_output)\n",
    "        \n",
    "        # dict speichern\n",
    "        resp_dict = json.loads(llm_output)\n",
    "        #print(resp_dict)\n",
    "\n",
    "        # durch dict iterieren\n",
    "        steps = resp_dict['steps']\n",
    "        final_result = resp_dict['final_answer']\n",
    "        \n",
    "        print(index, \" \", \"output:  \", final_result)\n",
    "\n",
    "        # Ergebnis in das DataFrame effizient speichern\n",
    "        results_gemini_df.loc[row_counter] = [index, text, steps, final_result]\n",
    "        row_counter += 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Fehlerbehandlung, wenn etwas beim API-Aufruf oder Speichern schiefgeht\n",
    "        print(f\"Fehler bei der Verarbeitung der Zeile {index}: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbdb63-e2c6-42e3-bc4f-92df04f015d0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gemini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b62ee-b699-49f6-81dd-0548e9b5db85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Datenaufbereitung \n",
    "\n",
    "# Entferne Zeilenumbrüche und Leerzeichen aus der Spalte 'generated_label'\n",
    "results_gemini_df['generated_label'] = results_gemini_df['generated_label'].str.strip()\n",
    "\n",
    "# Wandelt die Werte in Kleinbuchstaben um\n",
    "results_gemini_df['generated_label'] = results_gemini_df['generated_label'].str.lower()\n",
    "\n",
    "# Mapping: 'negative' zu 0, 'positive' zu 1\n",
    "results_gemini_df_final = results_gemini_df # [results_gpt_df['generated_label'].isin(['0', '1',0,1])]\n",
    "\n",
    "results_gemini_df_final['generated_label'] = results_gemini_df_final['generated_label'].replace({\n",
    "    'negative': 0, \n",
    "    'negativ': 0, \n",
    "    'positive': 1, \n",
    "    'positiv': 1, \n",
    "    'neutral': 2\n",
    "})\n",
    "\n",
    "# Filtert den DataFrame, um nur Zeilen zu behalten, bei denen der Wert in 'generated_label' 0 oder 1 ist\n",
    "results_gemini_df_final_ver = results_gemini_df_final[results_gemini_df_final['generated_label'].isin([0, 1, 2])]\n",
    "\n",
    "# als int formatieren\n",
    "results_gemini_df_final_ver['generated_label'] = results_gemini_df_final_ver['generated_label'].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a26c60-b3fa-4aa6-a5d9-59d12cf672a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_gemini_df_final_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b8564-7f07-4de4-b4d1-4a623c38b6b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# CSV abspeichern \n",
    "results_gemini_df_final_ver.to_csv('/Users/marvinschmitt/Library/CloudStorage/OneDrive-Persönlich/M.Sc. Data Science/17 Masterarbeit/Repo/Prod/CSVs/SC_SB10k_ZeroShot_CoT_GEMINI.csv', encoding='utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69bd19b-62e1-48d2-bd0c-b33dc81da6a3",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d883a89-e7a3-4b88-8803-247d9c1dffb4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Beide DataFrames anhand der 'index'-Spalte mergen\n",
    "df_combined = pd.merge(sb10k_subset, results_gemini_df_final_ver, on='index')\n",
    "\n",
    "# Die Spalten 'label' und 'generated_label' sollten die tatsächlichen und vorhergesagten Labels enthalten\n",
    "true_labels = df_combined['sentiment_coded']  # Tatsächliche Labels (z.B. aus SST2)\n",
    "predicted_labels = df_combined['generated_label']  # Vorhergesagte Labels (z.B. aus GPT)\n",
    "\n",
    "# 1. Accuracy (Genauigkeit)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# 2. Precision (Genauigkeit der Klassifikation für alle Klassen)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'Precision (macro): {precision:.2f}')\n",
    "\n",
    "# 3. Recall (Empfindlichkeit für alle Klassen)\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'Recall (macro): {recall:.2f}')\n",
    "\n",
    "# 4. F1-Score (harmonisches Mittel von Precision und Recall für alle Klassen)\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "print(f'F1-Score (macro): {f1:.2f}')\n",
    "\n",
    "# 5. Confusion Matrix (Verwirrungsmatrix)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=[0, 1, 2])\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be8f9e-4e8a-4df3-80a4-fe0ad6db5c03",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix berechnen (true_labels und predicted_labels sind die tatsächlichen und vorhergesagten Labels)\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Klassenlabels definieren\n",
    "class_names = ['negativ', 'positiv', 'neutral']\n",
    "\n",
    "# Confusion Matrix als Heatmap darstellen\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "# Achsen beschriften\n",
    "plt.xlabel('Vorhergesagte Labels')\n",
    "plt.ylabel('Tatsächliche Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Plot anzeigen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb7e34-c370-49fc-b56a-04012a869abe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666a664-3d2b-4da5-9a3c-953ff718c458",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad8cb6-55c8-4399-a605-01c0b06b689c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b396db-cd73-438f-aa03-6f37b8f1a090",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
